{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/amitrajitbose/handwritten-digit-recognition/blob/master/handwritten_digit_recognition_GPU.ipynb","timestamp":1667169255153}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"MHvuWIUHdIpt"},"cell_type":"markdown","source":["# VDL Exericse 1\n","\n","**Group Name:** ...\n","\n","\n","**Participants:**\n","\n","- Name 1 (Matrikl. Nr. 1)\n","- Name 2 (Matrikl. Nr. 2)\n","- ...\n","\n","\n","## Handwritten Digit Recognition in PyTorch\n","\n","In this exercise, we will use PyTorch to classify image sof handwritten digits. We will use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), which contains 28x28 images of handwritten digits from 0 to 9.\n","\n","We will download the dataset and create train, validation and test splits. The train set will be used to actually train our network, where as the validation set will only be used to visualize network's performance **during** training. Finally, the test set will be used to evaluate the accuracy of our network **after** the training has finished.\n","\n","Look for `TODO` tags in the notebook, and complete the missing code. There are 6 such tags in total, and each of them can give you up to 0.5 bonus mark."]},{"metadata":{"id":"oGjRmijsaXJ3"},"cell_type":"markdown","source":["### Necessary Imports"]},{"metadata":{"id":"TOyGrPT5ASDc"},"cell_type":"code","source":["# Import necessary packages\n","import numpy as np\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","from time import time"],"execution_count":null,"outputs":[]},{"metadata":{"id":"XPuuTDEfAfDy"},"cell_type":"code","source":["import os\n","from google.colab import drive"],"execution_count":null,"outputs":[]},{"metadata":{"id":"uLdtrS4zaeEs"},"cell_type":"markdown","source":["### Download the Dataset\n","\n","Torchvision provides many built-in datasets [here](https://pytorch.org/vision/stable/datasets.html) which can be directly downloaded and imported from the `torchvision.datasets` package. \n","\n","The first few lines of the code below download the train and test sets of the MNIST dataset. Complete the tasks described below by filling in the parts marked with `TODO:`.\n","\n","**Tasks:**\n","1. Split the train data into two parts; a train and a validation set with 80:20 ratio. See [`torch.utils.data.random_split`](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split). *Hint: Print the length of the original `trainset` to decide on the size of splits.*\n","2. Create three [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) objects for loading each of the datasets with a batch size of 64. Shuffle the train and validation data, but not the test data."]},{"metadata":{"id":"sZD2NGz2Ak6w"},"cell_type":"code","source":["from torch.utils.data import random_split\n","from torchvision import datasets, transforms\n","\n","\n","# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                              transforms.Normalize((0.5,), (0.5,)),\n","                              ])\n","\n","\n","# Download the dataset\n","trainset = datasets.MNIST('data/MNIST/', download=True, train=True, transform=transform)\n","testset = datasets.MNIST('data/MNIST/', download=True, train=False, transform=transform)\n","\n","\n","# TODO: Split the 'trainset' into train and validation sets, and \n","generator=torch.Generator().manual_seed(42)\n","\n","\n","# TODO: Create the three data loaders\n","batch_size=64\n","\n","\n","# Print the lengths of all three datasets\n","print('Train:', len(trainset), 'Val:', len(valset), 'Test:', len(testset))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"GcAfrn2falkK"},"cell_type":"markdown","source":["### Exploring The Data\n","\n","**Tasks:**\n","\n","3. Visualize samples from the dataset."]},{"metadata":{"id":"xOjlOyjcCezX"},"cell_type":"code","source":["dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","print(type(images))\n","print(images.shape)\n","print(labels.shape)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"EuBvOWmGDHOq"},"cell_type":"code","source":["plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"],"execution_count":null,"outputs":[]},{"metadata":{"id":"F9CppCcqDLtB"},"cell_type":"code","source":["# TODO: Use `plt` to visualize all 64 images in the first batch\n","# of the training set as an 8x8 grid.\n","figure = plt.figure()\n"],"execution_count":null,"outputs":[]},{"metadata":{"id":"lGyau0mOaP2m"},"cell_type":"markdown","source":["### Defining The Neural Network\n","\n","**Tasks:**\n","4. Create the network layers as shown below in the `CustomModel` class.\n","5. Implement the forward method."]},{"metadata":{"id":"n-NR96UtFSkB"},"cell_type":"markdown","source":["![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mlp_mnist.png)"]},{"metadata":{"id":"3WJXInzQGcAy"},"cell_type":"code","source":["from torch import nn\n","from torch.nn import Linear, LogSoftmax\n","\n","class CustomModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # TODO: Build the network layers shown in the diagram above\n","    input_size =  \n","    hidden_sizes = []\n","    output_size = \n","\n","  def forward(self, x):\n","    # TODO: Implement the forward pass\n","    return x\n","\n","\n","# Build a feed-forward network\n","model = CustomModel()\n","print(model)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"XyXEUFICQeqF"},"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"wstRGu4FaJBe"},"cell_type":"markdown","source":["### Train the Network\n","\n","**Tasks:**\n","6. Write the validation step."]},{"metadata":{"id":"oxSLypv2LOD-"},"cell_type":"code","source":["from torch import optim\n","\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_step(x, y, model, optimizer, criterion):\n","  \"\"\" One training step.\n","\n","  Args:\n","    x: a batch of input tensors from the training set.\n","    y: a batch of labels corresponding to the inputs.\n","    model: the network to train\n","    optimizer: the optimizer to use\n","    criterion: the loss criterion\n","\n","  Returns:\n","    the loss computer for this training step\n","  \"\"\"\n","  x = x.view(x.shape[0], -1) # Reshape to vector of size 784 (28x28=784)\n","  optimizer.zero_grad()      # Clear existing gradients\n","  output = model(x.cuda())   # Forward pass\n","  loss = criterion(output, labels.cuda())\n","  loss.backward()            # Compute new gradients\n","  optimizer.step()           # Update weights\n","  return loss"],"metadata":{"id":"-3WQkVMZLVbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def val_step(x, y, model, optimizer, criterion):\n","  \"\"\" One validation step.\n","\n","  Note that there are no gradient computations or weight updates \n","  during validation.\n","\n","  Args:\n","    x: a batch of input tensors from the validation set.\n","    y: a batch of labels corresponding to the inputs.\n","    model: the network to validate\n","    optimizer: the optimizer to use\n","    criterion: the loss criterion\n","\n","  Returns:\n","    the loss computer for this validation step\n","  \"\"\"\n","  # TODO: Implement the validation step\n","  return loss"],"metadata":{"id":"rPLKEY-ENgYA"},"execution_count":null,"outputs":[]},{"metadata":{"id":"XCsoAdjdLjPb"},"cell_type":"code","source":["time0 = time()\n","epochs = 15\n","for e in range(epochs):\n","    # Training loop\n","    model.train()  # set to train mode\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        loss = train_step(images, labels, model, optimizer, criterion)\n","        running_loss += loss.item()\n","\n","    print(\"ep {}:\\ttrain={:.4f}\".format(e, running_loss/len(trainloader)), end='')\n","\n","    # Validation loop\n","    model.eval()  # set to evaluation mode\n","    running_loss = 0\n","    for images, labels in valloader:\n","        with torch.no_grad():\n","            loss = val_step(images, labels, model, optimizer, criterion)\n","            running_loss += loss.item()\n","\n","    print(\"\\tval={:.4f}\".format(running_loss/len(valloader)))\n","print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"],"execution_count":null,"outputs":[]},{"metadata":{"id":"75j9X1b6ME5K"},"cell_type":"code","source":["def view_classify(img, ps):\n","    ''' Function for viewing an image and it's predicted classes.\n","    '''\n","    ps = ps.cpu().data.numpy().squeeze()\n","\n","    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n","    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n","    ax1.axis('off')\n","    ax2.barh(np.arange(10), ps)\n","    ax2.set_aspect(0.1)\n","    ax2.set_yticks(np.arange(10))\n","    ax2.set_yticklabels(np.arange(10))\n","    ax2.set_title('Class Probability')\n","    ax2.set_xlim(0, 1.1)\n","    plt.tight_layout()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Ie9Fffl_Mqp6"},"cell_type":"code","source":["images, labels = next(iter(testloader))\n","\n","img = images[0].view(1, 784)\n","# Turn off gradients to speed up this part\n","with torch.no_grad():\n","    logps = model(img.cuda())\n","\n","# Output of the network are log-probabilities, need to take exponential for probabilities\n","ps = torch.exp(logps)\n","probab = list(ps.cpu().numpy()[0])\n","print(\"Predicted Digit =\", probab.index(max(probab)))\n","view_classify(img.view(1, 28, 28), ps)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"wAEvDtiaM6RQ"},"cell_type":"markdown","source":["### Model Evaluation\n","\n","**Bonus Task:** Improve the test accuracy to above 95% by modifying network architecture or training parameters (e.g. optimizer, loss function, learning rate, etc.)."]},{"metadata":{"id":"5sBPmaBONPkT"},"cell_type":"code","source":["correct_count, all_count = 0, 0\n","for images,labels in testloader:\n","  for i in range(len(labels)):\n","    img = images[i].view(1, 784)\n","    # Turn off gradients to speed up this part\n","    with torch.no_grad():\n","        logps = model(img.cuda())\n","\n","    # Output of the network are log-probabilities, need to take exponential for probabilities\n","    ps = torch.exp(logps)\n","    probab = list(ps.cpu().numpy()[0])\n","    pred_label = probab.index(max(probab))\n","    true_label = labels.numpy()[i]\n","    if(true_label == pred_label):\n","      correct_count += 1\n","    all_count += 1\n","\n","print(\"Number Of Images Tested =\", all_count)\n","print(f\"\\nModel Accuracy = {(correct_count/all_count*100)}%\")"],"execution_count":null,"outputs":[]}]}